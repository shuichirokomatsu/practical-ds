---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region -->
<!--- 全体の交通整理 --->

# データ分析のプロセス


課題や目標が設定され、動き出したデータ分析のプロジェクトは、いつも直線に進んでいく訳ではありません。

的な道のりでないことがしばしばあります。

最初の段階として、利用するデータの読み込みが思うようにいかなかったりしてつまづいてしまうこともあります。それが済んだらデータを整理・整形する作業が発生します。多くのデータは入力された状態でコンピュータが利用しやすい形式とは異なっているためです。

<!--tidy data -->

そしてここからがさらに骨の折れる作業です。
今日のテーマもここの作業段階での話となります。具体的にはデータの加工・変形と可視化、そしてモデルの構築です。これらの作業は互いに繋がっている点に注意してください。


反復して行うことがしばしばあります。また一般的にデータをモデルに投入する前の加工作業を前処理と呼びますが、


効率的なモデルを開発する過程は

- 反復的

複数のモデルを構築し、調整や検証をすることになるでしょう。

![データ分析のワークフロー。Garrett and Hadley (2016) より作成](../images/tidy-workflow.png)

典型的な（もちろん常にこの通りに事が運ぶわけではありませんし、繰り返しの数にも差がありますし、後戻りも必要になるでしょう。）

モデルの実行以外にも

これらはモデル構築の作業と紐づいています。モデルの結果からさらなる処理を加えていくことでモデルを磨き上げていくのです。
探索的なデータ分析、定量分析、特徴量エンジニアリング



可視化やモデルを実行した結果は垂れ流しにしておくわけには行きません。どのような手段にせその結果を伝達することが必要になります。


といった作業があります。

- 「何を解くか」
- ドメイン知識が求められることも

直感に基づく初期モデル
<!-- #endregion -->

<!-- #region -->
## 問題設定とモデル

- モデルに応じて、データの分布などに仮定をおいているものがある
    - 仮定に合わないデータを与えた場合、適切な結果が得られない恐れがある
    - ... 特徴量エンジニアリング
    - e.g. 線形モデル... 誤差が等分散正規分布であることを仮定
        - 正規分布に従わない場合は一般化線形モデルを利用するなどの対処
    - e.g. K-meansクラスタリング... 各クラスタが同じ大きさ
        - クラスタの大きさに偏りがある場合には混合正規分布の利用を検討
- ノーフリーランチ定理
    - あらゆる問題で性能の良い万能なモデル・アルゴリズムは存在しない
    - 問題・目的に適したモデルを選択する

### 回帰

- 入力xから実数の出力yを予測
- 線形または非線形な関係を記述
- パラメータ推定

## 分類 (判別)

- 入力xからカテゴリの出力yを予測
- 線形または非線形な関係を記述
- パラメータ推定

### クラスタリング

- 混合正規分布
- トピックモデル、LDA

ここでは各手法についての説明は行いません。データ分析、機械学習についての専門書は多く出版されているため、末尾の参考文献をご覧ください。

<!-- ds メインということを忘れなく-->

- 教師あり学習
- 教師なし学習

## データの持つ意味

- データ型に基づく分類
    - 数値
    - カテゴリ
        - 順序つき
    - 論理値
    - 文字列
- 尺度を元にした分類
   - 名義尺度
   - 順序尺度
   - 間隔尺度
   - 比例尺度
- 特殊系
    - 日付・時間
    - 地理空間・座標
   
- 機械学習モデルでは数値データを入力の前提にしているものが多い

### データを特徴量に落とし込む

データをモデルに当てはめる、アルゴリズムによる計算を実行するには数値化が必要になります。

多くのデータは数値化されていますが、

また、すでに数値となっているデータに対しても、より良い特徴量として扱うために変換処理を加えることがあります。


- 表形式のデータでは、行に観測が記録され、複数の列からなる特徴量が含まれる
- 一つの文書や一回のつぶやきが観測され、フレーズや単語が特徴になる
- 画像データでは、色や線の情報を特徴量として利用する


### 特徴量エンジニアリング

特徴量エンジニアリングは

- 特徴量エンジニアリング... モデルに適した形（数値）への変換
* 前処理（クレンジング）との比較...
    * 前処理は減算のプロセス
    * 特徴量エンジニアリングは（主に）加算のプロセス
        - 変数を減らすこともある

- データの持つ特徴を強調することもできる
- 知識をデータに反映させる
    - ドメイン知識
- 共通の「知識」も活用できる... この方法を紹介する

"Garbage in, garbage out"

- 問題の本質は何か?
- どのように相互作用をもたらすか

5つのベストプラクティス

モデルが識別可能な形式に処理する必要がある

予測モデルの種類（線形モデル、KNN、ニューラルネットワークなどのモデルか決定木やランダムフォレストを利用する木ベースのモデルか）と

データの種類に応じて適用する前処理が異なる

### どうして特徴量エンジニアリングが必要なのか

- 価値のある特徴量を作成、ノイズをもたらす特徴量を除去する... 精度の高いモデルを構築する

モデルの性能に大きな影響を及ぼす
特定の特徴量を組み合わせることでモデルの性能が向上することがある

データを数値的に表現する方法はいくらも存在する

入力に与えられた変数から出力変数の値を予測・分類する... パターンを掴むことが大事。

特徴量はパターンと言い換えても良いでしょう。

生データと呼ぶことがりますが、生データのままでは特徴を表現することが難しいことがあります。

特徴量エンジニアリングによってデータのパターンを見出しやすくするようにするのが我々の仕事になります。

- 代表的な変数を選ぶこと、集約すること
<!-- #endregion -->

日付

- 日付を構成する年月日を別々の変数として扱う（個々の要素は数値になる）
- 年間での経過日数
- 休日であったか、休暇中であったかなど

ビールの売り上げ

- 年はそれほど重要ではない。夏の気温が高い時期（6月から9月ごろ）が重要そう。日にちは関係するだろうか?
- 夏... 150~日め??
- 平日よりも休日

<!-- ref) 02/date-and-time -->

これらを表現する方法を選び出すことが重要になります。

#### 特徴量エンジニアリングのサブタスク

<!-- Sub-Problems of Feature Engineering -->

- 特徴をモデルに落とし込む
- 変数重要度
- 特徴抽出
- 特徴量選択
    - フィルタ法... 無関係な特徴,相関
    - 反復特徴量選択
    - モデル組み込み
- 特徴量の構築、組み合わせ、集約


### 特徴量エンジニアリング以外で重要なこと

- データセットの分割
- モデル性能評価の指標
- パラメータ調整

モデルのパラメータはモデルの外部にあり、データからは推定できない。
用意された初期値や経験則、試行錯誤によって最適値を見出す

機械学習モデルの全体的な動作を制御するため、非常に重要
事前に定義された損失関数を最小化する

ハイパーパラメータの組み合わせを見つける
然もなくば、モデルが収束して損失関数を効率的に最小化できないことで良い結果が得られない

グリッドサーチ、ベイジアン最適化など

(Kaggleではより良い性能のモデルを求められるが、実用的には最適化は突き詰める必要がないかもしれない... 時間とのトレードオフ。特徴量を磨き上げる方が重要)

### 特徴空間


## 本書の構成

0. 全体像を把握する
1. 特徴量エンジニアリング各論（多種多様なデータに対応できるように）

### 対象とする読者

### ゴール
