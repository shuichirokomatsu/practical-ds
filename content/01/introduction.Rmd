---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.1.3
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region -->

# データ分析のプロセス

課題や目標が設定され、動き出したデータ分析のプロジェクトは、いつも直線に進んでいく訳ではありません。最初の段階として、利用するデータの読み込みが思うようにいかなかったりしてつまづいてしまうこともあります。それが済んだらデータを整理・整形する作業が発生します。多くのデータは入力された状態でコンピュータが利用しやすい形式とは異なっているためです。

そしてここからがさらに骨の折れる作業です。本書のテーマもここの作業段階での話となります。具体的にはデータの加工・変形と可視化、そしてモデルの構築です。これらの作業は互いに繋がっている点に注意してください。加えて、これらの作業は反復的に行われることが前提です。一般的にデータをモデルに投入する前の加工作業を前処理と呼びますが、複数のモデルを構築し、調整や検証をすることになるでしょう。この段階の作業の詳細は[次の章](../01/tidymodels-workflow)で解説します。

![データ分析のワークフロー。Garrett and Hadley (2016) より作成](../images/tidy-workflow.png)

ここでは全体的なデータ分析のワークフローを俯瞰して考えてみることにします。まず、データが用意されたら問題設定を明らかにすること、そして問題解決のためのモデルについて考える必要があります。

- データが与えられた
- このデータを使って何を明らかにすることが目的か、またその結果をどのように使い、何を得たいのか
- システム設計
    - 問題を構成します。
    - データの特徴や目的により特定していく


典型的な（もちろん常にこの通りに事が運ぶわけではありませんし、繰り返しの数にも差がありますし、後戻りも必要になるでしょう。）

モデルの実行以外にも

可視化やモデルを実行した結果は垂れ流しにしておくわけには行きません。どのような手段にせその結果を伝達することが必要になります。

## 問題設定とモデル

- モデルに応じて、データの分布などに仮定をおいているものがある
    - 仮定に合わないデータを与えた場合、適切な結果が得られない恐れがある
    - ... 特徴量エンジニアリング
    - e.g. 線形モデル... 誤差が等分散正規分布であることを仮定
        - 正規分布に従わない場合は一般化線形モデルを利用するなどの対処
    - e.g. K-meansクラスタリング... 各クラスタが同じ大きさ
        - クラスタの大きさに偏りがある場合には混合正規分布の利用を検討
- ノーフリーランチ定理
    - あらゆる問題で性能の良い万能なモデル・アルゴリズムは存在しない
    - 問題・目的に適したモデルを選択することが重要

### 回帰

- 入力xから実数の出力yを予測
- 線形または非線形な関係を記述
- パラメータ推定

## 分類 (判別)

- 入力xからカテゴリの出力yを予測
- 線形または非線形な関係を記述
- パラメータ推定

### クラスタリング

- 混合正規分布
- トピックモデル、LDA

ここでは各手法についての説明は行いません。データ分析、機械学習についての専門書は多く出版されているため、巻末の参考文献の一覧をご覧ください。

<!-- ds メインということを忘れなく-->

- 教師あり学習
- 教師なし学習

## データの持つ意味

- データ型に基づく分類
    - 数値... 量を表現する
    - カテゴリ... 決められた選択肢の中から項目を示す
        - 順序つき
    - 論理値... 二値によって表現される
- 尺度を元にした分類
   - 名義尺度
   - 順序尺度
   - 間隔尺度
   - 比例尺度
- 特殊系... ドメイン知識が必要・あると役立つ応用的な特徴量エンジニアリング
    - 文字列
    - 日付・時間
    - 地理空間・座標
    - 画像
   
- 機械学習モデルでは数値データを入力の前提にしているものが多い

### 情報をデータとして利用可能にする

データをモデルに当てはめる、アルゴリズムによる計算を実行するには数値化が必要になります。言い換えるとデータをモデルが識別可能な形式に処理する必要があります
。多くのデータは数値化されていますが、ログデータ、文書をコンピュータで利用可能にした段階では数値化されていないことが多いです。画像データもバイナリファイルなので元のデータは数値ではないはずです。

また、すでに数値となっているデータに対しても、より良い特徴量として扱うために変換処理を加えることがあります。これらはモデルにデータの良い特徴を与えるための作業であり、データの前処理や特徴量エンジニアリングの作業です。各種のデータに対して、特徴量エンジニアリングが求められる状況は次のものがあります。

- 表形式のデータでは、行に観測が記録され、複数の列からなる特徴量が含まれる
- 一つの文書や一回のつぶやきが観測され、フレーズや単語が特徴になる
- 画像データでは、色や線の情報を特徴量として利用する

予測モデルの種類（線形モデル、KNN、ニューラルネットワークなどのモデルか決定木やランダムフォレストを利用する木ベースのモデルか）とデータの種類に応じて適用する前処理、特徴量エンジニアリングが異なります。

### 特徴量エンジニアリング

特徴量エンジニアリングは、モデルに適した形（数値）への変換と述べました。では前処理との違いは何でしょうか。前処理はクレンジングとも呼ばれ、基本的には減算のプロセスです。データから不要な情報を削除したり、欠損や異常値を取り除いたりします。対する特徴量エンジニアリングは変数を減らすこともありますが情報を減らすことはほぼありません。本書では特徴量エンジニアリングは（主に）加算のプロセスとして前処理と区別することにします。

また特徴量エンジニアリングは、よりモデルの性能に直結する作業です。それは既存の変数を加工することでその情報を強調することができるためです。一般的なデータ分析モデルで有効な特徴量エンジニアリングの手法がいくつかあります。これらは「守り」の特徴量エンジニアリングと考えられます。有効な、と言いましたが一方で必要な処理を施していない場合にはモデルの性能が低いままのものがあるためです。一方でドメイン知識と呼ばれるデータの背景を理解している場合に活用可能な情報を組み込むことも可能です。これは「攻め」の特徴量エンジニアリングです。すべての人がドメイン知識をもっている訳ではありません。「攻め」の特徴量エンジニアリングは、データとモデルの関係についての背景知識があってこその武器となるのです。

<!-- "Garbage in, garbage out"
- 問題の本質は何か?
- どのように相互作用をもたらすか
5つのベストプラクティス -->

### どうして特徴量エンジニアリングが必要なのか

- 価値のある特徴量を作成、ノイズをもたらす特徴量を除去する... 精度の高いモデルを構築する

モデルの性能に大きな影響を及ぼす
特定の特徴量を組み合わせることでモデルの性能が向上することがある

データを数値的に表現する方法はいくらも存在する

入力に与えられた変数から出力変数の値を予測・分類する... パターンを掴むことが大事。

特徴量はパターンと言い換えても良いでしょう。

生データと呼ぶことがりますが、生データのままでは特徴を表現することが難しいことがあります。

特徴量エンジニアリングによってデータのパターンを見出しやすくするようにするのが我々の仕事になります。

- 代表的な変数を選ぶこと、集約すること
<!-- #endregion -->

日付

- 日付を構成する年月日を別々の変数として扱う（個々の要素は数値になる）
- 年間での経過日数
- 休日であったか、休暇中であったかなど

ビールの売り上げ

- 年はそれほど重要ではない。夏の気温が高い時期（6月から9月ごろ）が重要そう。日にちは関係するだろうか?
- 夏... 150~日め??
- 平日よりも休日

<!-- ref) 02/date-and-time -->

これらを表現する方法を選び出すことが重要になります。

#### 特徴量エンジニアリングのサブタスク

<!-- Sub-Problems of Feature Engineering -->

- 特徴をモデルに落とし込む
- 変数重要度
- 特徴抽出
- 特徴量選択
    - フィルタ法... 無関係な特徴,相関
    - 反復特徴量選択
    - モデル組み込み
- 特徴量の構築、組み合わせ、集約


### 特徴量エンジニアリング以外で重要なこと

- データセットの分割
- モデル性能評価の指標
- パラメータ調整

モデルのパラメータはモデルの外部にあり、データからは推定できない。
用意された初期値や経験則、試行錯誤によって最適値を見出す

機械学習モデルの全体的な動作を制御するため、非常に重要
事前に定義された損失関数を最小化する

ハイパーパラメータの組み合わせを見つける
然もなくば、モデルが収束して損失関数を効率的に最小化できないことで良い結果が得られない

グリッドサーチ、ベイジアン最適化など

(Kaggleではより良い性能のモデルを求められるが、実用的には最適化は突き詰める必要がないかもしれない... 時間とのトレードオフ。特徴量を磨き上げる方が重要)
