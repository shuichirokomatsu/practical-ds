{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_output": true,
    "name": "setup",
    "results": "\"hide\""
   },
   "outputs": [],
   "source": [
    "source(here::here(\"R/setup.R\"))\n",
    "df_hazard <- \n",
    "  df_hazard %>% \n",
    "  st_drop_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カテゴリデータの取り扱い\n",
    "\n",
    "ダミー変数の作成\n",
    "\n",
    "カテゴリデータが表現する値は連続的に変化するものではありません。\n",
    "\n",
    "多くの統計・機械学習モデルでは、数値化を求めます。\n",
    "\n",
    "だめ... SVM、ニューラルネットワーク\n",
    "\n",
    "xgboost, glmnet etc.\n",
    "\n",
    "カテゴリの変数には、次にあげる特徴が含まれる場合があります。\n",
    "\n",
    "1. 大小または順序関係\n",
    "2. 重み\n",
    "\n",
    "ここで紹介する多くの特徴量エンジニアリングは、カテゴリ変数がもつ特徴を考慮しつつ、数値化するものとなります。\n",
    "\n",
    "定性的\n",
    "\n",
    "一方で、数値のように扱える郵便番号などは数値として扱ってはいけません。これらは数値出会っても大小関係や連続的な意味をもたないためです。\n",
    "\n",
    "「どれだけ違うか」ではなく「値が異なることが重要」\n",
    "\n",
    "メッシュコード\n",
    "\n",
    "尺度の問題？？\n",
    "\n",
    "カテゴリに順序を与える\n",
    "大きさを示す変数として「大」、「中」、「小」の3項目がある場合、「大」は「小」よりも大きいことはわかります。この関係は1から3の数値に示すことが可能で、大は一番大きな値である3と対応するという変換を行うことができます。\n",
    "\n",
    "<!-- ここではビールへの支出データおよび土砂災害・雪崩メッシュデータを利用します。 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": true,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "library(cattonum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": false
   },
   "outputs": [],
   "source": [
    "df_beer2018q2\n",
    "df_hazard\n",
    "df_lp_kanto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ変数の特徴量エンジニアリングには、次元を増やす、増やさないの両方のパターンがあります。\n",
    "\n",
    "それぞれの方法をみていきましょう。\n",
    "\n",
    "色々ある。これで全てではない。weight of evidenceなど。\n",
    "\n",
    "カテゴリを数値に変換する処理のことを全般的にエンコーディング\n",
    "\n",
    "## ビンカウンティング\n",
    "\n",
    "統計量を当てはめるのをビンカウンティング\n",
    "\n",
    "### カウントエンコーディング\n",
    "\n",
    "カウント変数の項目に対して、頻度を求めたものがカウントエンコーディングです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1236)\n",
    "df <- \n",
    "  df_hazard %>% \n",
    "  sample_n(10) %>% \n",
    "  select(hazardDate, hazardType, maxRainfall_h)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようなデータに対して、hazardTypeのカウントエンコーディングを適用すると次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df %>% \n",
    "  group_by(hazardType) %>% \n",
    "  mutate(hazardDate,\n",
    "            hazardType_ = n(),\n",
    "            maxRainfall_h) %>% \n",
    "  ungroup() %>% \n",
    "  select(hazardDate, hazardType = hazardType_, maxRainfall_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カテゴリ内での出現頻度が多ければ多いほど、特徴量の値は大きくなり、影響も強くなります。一方で、元は異なる水準であったものが同じ出現頻度であった場合にはエンコード後の値が同じになってしまうことに注意です。例では、出現頻度が1の「地すべり」と「雪崩」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベルエンコーディング\n",
    "\n",
    "ラベルエンコーディング (label encoding) はカテゴリに対して一意の数値を割り振るというアイデアが単純なものですが、それではカテゴリがもつ特徴を拾い上げることはできません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df_hazard %>% \n",
    "  st_drop_geometry() %>% \n",
    "  group_by(hazardType) %>% \n",
    "  slice(1:2L) %>% \n",
    "  ungroup() %>% \n",
    "  distinct(hazardType, hazardType_sub, .keep_all = TRUE) %>% \n",
    "  select(hazardType) %>% \n",
    "  mutate(hazardType_num = as.numeric(as.factor(hazardType))) %>% \n",
    "  head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ターゲットエンコーディング\n",
    "\n",
    "ターゲットエンコーディング (target-based encoding, likelihood encoding) は、カテゴリ変数と対応する目的変数の値を利用した方法です。カテゴリ変数の水準ごとに、水準の項目を目的変数の平均値に置き換えるという処理を行います。例えば、カテゴリ変数にAという項目が4つ含まれ、それぞれに1.5, 3.0, 0, 1.2のoutcomeが与えられているとします。この場合、outcomeの平均値は1.425なので、カテゴリ変数のAは1.425に置き換えられます。また以下のように目的変数が論理値である場合には、それを数値に変換した値を利用します（RではTRUEが1、FALSEが0）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- \n",
    "  tibble(\n",
    "  feature = c(\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"C\"),\n",
    "  outcome = c(TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE)) %>% \n",
    "  add_count(feature)\n",
    "\n",
    "df\n",
    "\n",
    "df %>% \n",
    "  mutate(outcome = as.numeric(outcome)) %>% \n",
    "  catto_mean(response = outcome)\n",
    "\n",
    "# df_target_enc <- \n",
    "#   df %>% \n",
    "#   add_count(feature) %>%\n",
    "#   group_by(feature) %>% \n",
    "#   mutate(mean_encode = sum(outcome) / n) %>% \n",
    "#   ungroup() %>% \n",
    "#   select(-feature)\n",
    "# \n",
    "# df_target_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データリークを起こしてしまう問題がある。\n",
    "\n",
    "また\n",
    "\n",
    "頻度の低い水準がある場合も過学習の原因になってしまう可能性がある。\n",
    "\n",
    "#### Leave one out エンコーディング\n",
    "\n",
    "ターゲットエンコーディングの計算において、\n",
    "\n",
    "データリークを防ぐように\n",
    "\n",
    "自身を除いて計算します。\n",
    "\n",
    "完全に防げるわけではない?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# df_target_enc %>% \n",
    "#   group_by(feature) %>% \n",
    "#   mutate(loo_encode = lead(outcome))\n",
    "\n",
    "df %>% \n",
    "  mutate(outcome = as.numeric(outcome)) %>% \n",
    "  catto_loo(response = outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "\n",
    "## ダミー変数化\n",
    "\n",
    "カテゴリ変数を数値に変換する処理として最も一般的なのが、カテゴリ変数をダミー変数化してしまうことです。カテゴリに含まれる水準の値を特徴量に直接用いるもので、ダミーコーディング、one-hotエンコーディング、effectコーディングの3種類があります。これらはカテゴリに含まれるk種類の値を特徴量として扱う際の挙動が異なります。\n",
    "\n",
    "### ダミーコーディング\n",
    "\n",
    "ダミーコーディングは統計分析でも広く使われるカテゴリ変数の数値化手法です。該当する値を含む場合に1、そうでなければ0を各特徴量に与えます。ダミーコーディングではカテゴリが取りうる数、自由度 k-1の特徴量を生成します。自由度 k-1 で十分である理由は、他のダミー変数の値から残りの一つの値が推測可能だからです。\n",
    "\n",
    "具体例で示しましょう。3つの水準 (A, B, C)をもつカテゴリ変数をダミーコーディングすると、2つの特徴量ができます。ここでは`feature_B`,`feature_C`という名前をつけました。ここで、Aをもつデータを探すのは簡単です。ダミー変数には0と1の値が格納され、該当しない場合には0ですので`feature_B`,`feature_C`両方で0のデータがAになります。Aのようなダミー変数に含まれないカテゴリは参照カテゴリと呼ばれます。参照カテゴリに対して、`feature_B`、`feature_C`の値が決まります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df %>% \n",
    "  recipe(~ feature) %>% \n",
    "  step_dummy(feature) %>% \n",
    "  prep() %>% \n",
    "  juice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダミーコーディングを利用したモデリングはその結果の解釈が容易になります。これを地価公示データの都市計画区分 (`urban_planning_area`) をダミー変数化することで示しましょう。都市計画区分の列は次に示すように4つの値を取りますが、1つを参照カテゴリとして扱い、3つのダミー変数で表現することになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "unique(df_lp_kanto$urban_planning_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_kanto_dummy_baked <- \n",
    "  df_lp_kanto %>% \n",
    "  recipe(posted_land_price ~ .) %>% \n",
    "  step_dummy(urban_planning_area) %>% \n",
    "  prep() %>% \n",
    "  bake(posted_land_price, starts_with(\"urban_planning_area\"), new_data = df_lp_kanto)\n",
    "\n",
    "df_lp_kanto_dummy_baked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "都市計画区分の情報のみを使って、公示価格を予測する線形回帰モデルを適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_kanto_dummy_baked %>% \n",
    "  lm(posted_land_price ~ ., data = .) %>% \n",
    "  tidy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定された結果の切片は、参照カテゴリの平均値を示します。つまり「市街化」の効果です。市街化に対して、他の係数はいずれも負値を取っています。これは市街化の影響が地下価格に影響し、他のカテゴリは効果が小さいことを示す結果です。ダミーエンコーディングではカテゴリの水準の一つを切片として利用可能なため、モデルの解釈が容易になるのです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_lp_kanto %>% \n",
    "  ggplot(aes(urban_planning_area, posted_land_price)) +\n",
    "  geom_bar(stat = \"identity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フルランク未満のエンコーディングは One-hotエンコーディング\n",
    "\n",
    "- ダミー変数が多くなると次元の数が増える (データ件数を上回ることも)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hotエンコーディング\n",
    "\n",
    "カテゴリ変数に含まれる項目を新たな列として扱い、各列の値には0または1を与えていく方法をOne-hotエンコーディングと言います。\n",
    "\n",
    "カテゴリに該当する場合は1、そうでない場合には0を与えていく方法です（ある要素が1で他の要素が0であるようにする表現をone-hot表現と呼びます）。\n",
    "\n",
    "ダミー変数とは異なり、ターゲットの項目も残るのが特徴です。\n",
    "\n",
    "この変数に対してOne-hotエンコーディングを行うと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_kanto$urban_planning_area %>% unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_kanto %>% \n",
    "  recipe(~ .) %>% \n",
    "  step_dummy(urban_planning_area, one_hot = TRUE) %>% \n",
    "  prep() %>% \n",
    "  bake(starts_with(\"urban_planning_area\"), new_data = df_lp_kanto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はカテゴリの水準数が4であったために4つの特徴量が新たに作られました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baked_split_date %>% \n",
    "  recipe(expense ~ .) %>% \n",
    "  step_dummy(date_dow, one_hot = TRUE) %>% \n",
    "  prep(training = df_baked_split_date) %>% \n",
    "  bake(new_data = df_baked_split_date) %>% \n",
    "  select(starts_with(\"date_dow\"), everything())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> カテゴリ数に応じて列数が増えることや、新しい値が出現する度に列数を増やす必要があることが問題点\n",
    "\n",
    "ダミーコーディングでは、カテゴリが多い場合にデータサイズが増大し、さらに大量の0と一部の1を含んだスパースデータ (sparse data) になりやすいことに留意しましょう。カテゴリの数が多い場合には次の特徴量ハッシュやビンカウンティングが有効です。\n",
    "\n",
    "<!-- スパースデータは計算コストが大きくなります -->\n",
    "\n",
    "### effectコーディング\n",
    "\n",
    "## カテゴリ変数の縮約・拡張\n",
    "\n",
    "### Polynomial encoding\n",
    "\n",
    "### Expansion encoding\n",
    "\n",
    "ビールの支出データに含まれるweatherdaytime_06_00_18_00には、「晴」や「曇」だけでなく「曇一時雨」や「雨後時々曇」といった気象に関する項目が含まれます。項目の組み合わせによる表現が可能であるため、カテゴリの数は多くなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beer2018q2 %>% \n",
    "  count(weatherdaytime_06_00_18_00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この一次や時々によって区切ることが可能な項目\n",
    "\n",
    "を新たな特徴量として活用するのがexpansion encodingになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beer2018q2_baked <- \n",
    "  df_beer2018q2 %>% \n",
    "  select(date, expense, weatherdaytime_06_00_18_00) %>% \n",
    "  tidyr::separate(weatherdaytime_06_00_18_00, \n",
    "                  sep = \"(後一時|一時|後時々|時々|後)\", \n",
    "                  into = paste(\"weatherdaytime_06_00_18_00\", \n",
    "                                c(\"main\", \"sub\"),\n",
    "                               sep = \"_\"))\n",
    "\n",
    "df_beer2018q2_baked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複雑なカテゴリを評価するのではなく、大雑把なカテゴリとして扱いたい場合にはカテゴリの項目を減らすことが有効でしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beer2018q2_baked %>% \n",
    "  count(weatherdaytime_06_00_18_00_main,\n",
    "        weatherdaytime_06_00_18_00_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多くのカテゴリを持つ場合の処理\n",
    "\n",
    "ビンカウンティング以外の方法を紹介します。\n",
    "\n",
    "<!-- 次元削減の項目も参照 -->\n",
    "\n",
    "### ターゲットエンコーディングの平滑化処理\n",
    "\n",
    "### 特徴量ハッシング\n",
    "\n",
    "ハッシュ関数を利用した\n",
    "\n",
    "固定の配列に変換する\n",
    "\n",
    "## まとめ\n",
    "\n",
    "- カテゴリ変数はツリーベースのモデルを除いて、モデルに適用可能な状態、数値に変換する必要がある\n",
    "- もっとも単純なものはカテゴリに含まれる値を独立した変数として扱うこと\n",
    "    - カテゴリ内の順序を考慮するには別な方法が必要\n",
    "- テキストも同様に数値化が必要。一般的には頻度の少ない単語が除外される。\n",
    "\n",
    "## 関連項目\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "- Max Kuhn and Kjell Johnson (2013). Applied Predictive Modeling (Springer)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
