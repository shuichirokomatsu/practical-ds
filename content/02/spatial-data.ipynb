{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "eval": true,
    "hide_output": true,
    "name": "setup",
    "results": "\"hide\"",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "─ \u001b[1mAttaching packages\u001b[22m ────────────────── tidyverse 1.2.1 ─\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.2.0     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 0.8.3     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.4.0\n",
      "─ \u001b[1mConflicts\u001b[22m ─────────────────── tidyverse_conflicts() ─\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mflatten()\u001b[39m masks \u001b[34mjsonlite\u001b[39m::flatten()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
      "Registered S3 method overwritten by 'xts':\n",
      "  method     from\n",
      "  as.zoo.xts zoo \n",
      "─ \u001b[1mAttaching packages\u001b[22m ───────────────── tidymodels 0.0.2 ─\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.5.2       \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.5  \n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.2       \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.4  \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.4.0.\u001b[31m1\u001b[39m     \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.3  \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.0.2       \n",
      "─ \u001b[1mConflicts\u001b[22m ─────────────────── tidymodels_conflicts() ─\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mflatten()\u001b[39m  masks \u001b[34mjsonlite\u001b[39m::flatten()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "Linking to GEOS 3.7.1, GDAL 2.4.1, PROJ 6.0.0\n",
      "\n",
      "Attaching package: ‘ensurer’\n",
      "\n",
      "The following object is masked from ‘package:recipes’:\n",
      "\n",
      "    check\n",
      "\n",
      "\n",
      "Attaching package: ‘janitor’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    chisq.test, fisher.test\n",
      "\n",
      "\n",
      "Attaching package: ‘cowplot’\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    ggsave\n",
      "\n",
      "[conflicted] Will prefer \u001b[34mdplyr::filter\u001b[39m over any other package\n",
      "[conflicted] Will prefer \u001b[34mdplyr::select\u001b[39m over any other package\n",
      "[conflicted] Will prefer \u001b[34mrecipes::step\u001b[39m over any other package\n",
      "Warning message:\n",
      "“Running make() in a subdirectory of your project. \n",
      "This could cause problems if your file_in()/file_out()/knitr_in() files are relative paths.\n",
      "Please either\n",
      "  (1) run make() from your drake project root, or\n",
      "  (2) create a cache in your working directory with new_cache('path_name'), or\n",
      "  (3) supply a cache of your own (e.g. make(cache = your_cache))\n",
      "      whose folder name is not '.drake'.\n",
      "  running make() from: /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/content/02\n",
      "  drake project root:  /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds\n",
      "  cache directory:     /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/.drake”\u001b[32mtarget\u001b[39m sf_hazard\n",
      "\u001b[32mtarget\u001b[39m ne_knt\n",
      "Warning message:\n",
      "“target ne_knt warnings:\n",
      "  attribute variables are assumed to be spatially constant throughout all geometries”Target ne_knt messages:\n",
      "  although coordinates are longitude/latitude, st_intersection assumes that they are planar\n",
      "[conflicted] Removing existing preference\n",
      "[conflicted] Will prefer \u001b[34mdplyr::filter\u001b[39m over any other package\n",
      "[conflicted] Removing existing preference\n",
      "[conflicted] Will prefer \u001b[34mdplyr::select\u001b[39m over any other package\n",
      "[conflicted] Removing existing preference\n",
      "[conflicted] Will prefer \u001b[34mrecipes::step\u001b[39m over any other package\n",
      "Unloading targets from environment:\n",
      "  df_hazard_kys\n",
      "  sf_hazard\n",
      "  df_beer\n",
      "  ne_knt\n",
      "  ne_kys\n",
      "  ne_jpn\n",
      "  df_beer2018q2\n",
      "  df_lp_kanto\n",
      "  df_hazard\n",
      "  sf_hazard_kys\n",
      "Warning message:\n",
      "“Running make() in a subdirectory of your project. \n",
      "This could cause problems if your file_in()/file_out()/knitr_in() files are relative paths.\n",
      "Please either\n",
      "  (1) run make() from your drake project root, or\n",
      "  (2) create a cache in your working directory with new_cache('path_name'), or\n",
      "  (3) supply a cache of your own (e.g. make(cache = your_cache))\n",
      "      whose folder name is not '.drake'.\n",
      "  running make() from: /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/content/02\n",
      "  drake project root:  /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds\n",
      "  cache directory:     /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/.drake”\u001b[34mAll targets are already up to date.\u001b[39m\n",
      "Warning message:\n",
      "“Running make() in a subdirectory of your project. \n",
      "This could cause problems if your file_in()/file_out()/knitr_in() files are relative paths.\n",
      "Please either\n",
      "  (1) run make() from your drake project root, or\n",
      "  (2) create a cache in your working directory with new_cache('path_name'), or\n",
      "  (3) supply a cache of your own (e.g. make(cache = your_cache))\n",
      "      whose folder name is not '.drake'.\n",
      "  running make() from: /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/content/02\n",
      "  drake project root:  /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds\n",
      "  cache directory:     /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/.drake”\u001b[32mtarget\u001b[39m df_lp_kanto_clean\n",
      "Warning message:\n",
      "“Running make() in a subdirectory of your project. \n",
      "This could cause problems if your file_in()/file_out()/knitr_in() files are relative paths.\n",
      "Please either\n",
      "  (1) run make() from your drake project root, or\n",
      "  (2) create a cache in your working directory with new_cache('path_name'), or\n",
      "  (3) supply a cache of your own (e.g. make(cache = your_cache))\n",
      "      whose folder name is not '.drake'.\n",
      "  running make() from: /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/content/02\n",
      "  drake project root:  /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds\n",
      "  cache directory:     /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/.drake”\u001b[32mtarget\u001b[39m df_lp_kanto_prep\n",
      "Warning message:\n",
      "“Running make() in a subdirectory of your project. \n",
      "This could cause problems if your file_in()/file_out()/knitr_in() files are relative paths.\n",
      "Please either\n",
      "  (1) run make() from your drake project root, or\n",
      "  (2) create a cache in your working directory with new_cache('path_name'), or\n",
      "  (3) supply a cache of your own (e.g. make(cache = your_cache))\n",
      "      whose folder name is not '.drake'.\n",
      "  running make() from: /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/content/02\n",
      "  drake project root:  /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds\n",
      "  cache directory:     /Users/uri/Library/Mobile Documents/com~apple~CloudDocs/jupyter_book/practical-ds/.drake”\u001b[32mtarget\u001b[39m df_lp_kanto_sp_baked\n",
      "Target df_lp_kanto_sp_baked messages:\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  although coordinates are longitude/latitude, st_nearest_feature assumes that they are planar\n",
      "  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mfail\u001b[39m df_lp_kanto_sp_baked\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: Target `df_lp_kanto_sp_baked` failed. Call `diagnose(df_lp_kanto_sp_baked)` for details. Error message:\n   オブジェクト 'station' がありません \n",
     "output_type": "error",
     "traceback": [
      "Error: Target `df_lp_kanto_sp_baked` failed. Call `diagnose(df_lp_kanto_sp_baked)` for details. Error message:\n   オブジェクト 'station' がありません \nTraceback:\n",
      "1. source(here::here(\"R/prepared_landprice.R\"))",
      "2. withVisible(eval(ei, envir))",
      "3. eval(ei, envir)",
      "4. eval(ei, envir)",
      "5. drake::make(plan_land_price_spatial_fe)",
      "6. process_targets(config)",
      "7. run_native_backend(config)",
      "8. get(paste0(\"backend_\", parallelism), envir = getNamespace(\"drake\"))(config)",
      "9. loop_build(target = targets[i], config = config, downstream = targets[-seq_len(i)])",
      "10. conclude_build(build = build, config = config)",
      "11. handle_build_exceptions(target = target, meta = meta, config = config)",
      "12. drake_error(\"Target `\", target, \"` failed. Call `diagnose(\", \n  .     target, \")` for details. Error message:\\n  \", meta$error$message, \n  .     config = config)",
      "13. stop(..., call. = FALSE)"
     ]
    }
   ],
   "source": [
    "source(here::here(\"R/setup.R\"))\n",
    "source(here::here(\"R/prepared_landprice.R\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 地理空間データの取り扱い\n",
    "\n",
    "地理空間データは、スマートフォンやSNSの発達、各種センサーの普及に伴い利用機会が増えています。従来の統計調査や自然環境調査だけでなく、オープンデータやログデータなど、扱う媒介も増えてきており多様な分野・領域で扱われるデータ形式の1つです。なおここでいう地理空間データとは、なんらかのデータに対して地球上の空間的な位置を記録した位置情報を指します。\n",
    "\n",
    "一方で地理空間データは時系列のデータ同様、他のデータ形式とは異なる特徴を持っており、取り扱いにはいくつかの注意が必要です。また特徴量エンジニアリングの観点からは、位置の情報を利用してさまざまな特徴量を生成できます。\n",
    "\n",
    "模擬データの中には位置情報を扱うものは2つあります。地価公示データと土砂災害・雪崩メッシュデータです。これらを例にして地理空間データの特性を理解しつつ、特性を生かした特徴量エンジニアリングの手法について紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空間データの特徴\n",
    "\n",
    "まず空間データがどのようなものか確認しておきましょう。特性を知ることで、不適切な処理を施してしまう危険を回避し、さらによりよい特徴量エンジニアリングの発想が浮かんでくるかもしれません。\n",
    "\n",
    "### ラスタとベクタ\n",
    "\n",
    "地理空間データとして扱うデータはラスタとベクタデータに分かれます。\n",
    "\n",
    "ベクタデータは、現実世界に存在する地物（行政区域など実際には存在しないもの）をデータ上に示したものを指します。ベクタの週類は複数あり、特に点、線、面を扱う場面が多いです。地物は座標と属性情報をもち、地図上で表現可能です。この属性情報は、一般的にテーブル形式で格納され、図形情報と関連づけられています。\n",
    "\n",
    "- 座標と属性情報をもち、地図上で表現できる\n",
    "- ポリゴンは、(x,y)の座標値を結んだ閉じた線分として格納される\n",
    "\n",
    "ラスタデータは主題データ、連続データとも呼ばれ、一定領域を格子状のグリッドで囲んだデータになります。ラスタを構成する各グリッドには値が記録されていて、ピクセルに値を記録する画像データのような情報のまとまりとなっています。ラスタは時系列で重ねることができ、時系列の解析にも利用されます。\n",
    "\n",
    "模擬データはいずれもベクタデータです。今回ラスタは対象としません。\n",
    "\n",
    "### 座標参照系\n",
    "\n",
    "地球上の地物の位置を示すために、座標に加えて座標参照系 (Coordinate Reference System: CRS) の定義が必要になります。これは二次元の座標を地球上に投影するため、位置関係と紐づけて使われます。言い換えると、座標参照系が判明している時にのみ座標を地球の表面に置くことが可能です。\n",
    "\n",
    "「座標」にはXY座標を使ったものに加えて、緯度経度で表現されるものもあります (地理座標系)。また地図投影法により定義された値 (投影座標系)を座標として使うこともあります。\n",
    "\n",
    "地図上に地物を重ねる際、意図しない箇所に地物が表示されることがあります。これは地図データの座標系が異なることが原因で発生する問題の一つです。加えて座標系が異なるデータは普通距離が計算できません。この問題については後述します。\n",
    "\n",
    "ふだん扱う機会の多い、主要な座標参照系として次のものがあります。\n",
    "\n",
    "- 地理座標系\n",
    "    - SRID: 4326 (WGS84) 世界測地系、GPSなど\n",
    "    - SRID: 6668 (JDG2011) 日本測地系2011。東北地方太平洋沖地震による東日本での地殻変動の影響を反映\n",
    "    - SRID: 4612 (JDG2000) 日本測地系2000。\n",
    "- 投影座標系... 平面直角座標系\n",
    "    - SRID: 6669-6687 (JDG2011) 日本の公共測量で採用されている座標系。日本全体を19の地域に分割し、平面投影上の歪みを軽減している\n",
    "\n",
    "### 空間的影響\n",
    "\n",
    "地域という空間的な広がりやスケールを持つ対象を扱う地理空間データには、他のデータにはない独自の効果 (空間的影響)が存在します。空間的自己相関 (spatial autocorrelation) と空間的異質性 (spatial heterogeneity) です。\n",
    "\n",
    "空間的自己相関は時系列データの自己相関のように、互いに近い距離にあるものはより強く影響し合うという考え方です。実際に、人口が集中する地域は楕円状に人口が拡散し、円の外側ほど人口が少ないことがしばしば観察されます。そしてもう一つ、空間的異質性は、空間データの空間的な分散を仮定したものです。つまり、地域が異なれば傾向も異なるという特徴になります。\n",
    "\n",
    "一般に、回帰モデルでは誤差項 $\\epsilon$ が独立で正規分布に従うと仮定されます。ここでの分散均一は、地理空間データでは成立しないことがあります。ここで分散均一としてしまうと、地域性を考慮しないことになってしまいます。そこで地理空間データの回帰モデルでは分散不均一を前提としたモデルが組まれます。\n",
    "\n",
    "加えて、これらの問題は地理空間データに対して[交差検証](../03/data-splitting)を行う際にも発生します。これについては交差検証の章で議論しますが、地理的に偏りのあるデータをランダムに分割してしまうことで過学習やデータ漏洩に繋がる不安があります。\n",
    "\n",
    "本書ではこれまで地理空間データのモデルに対して、これらの問題を無視して行ってきました。空間構造を考慮することで、モデルがどのように改善されるか、既存のモデルではどのような問題があったかを改めて見ていきましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 住所の分解と丸め込み\n",
    "\n",
    "住所は一般に文字列によって構造化されています。我々は次の文字列をみたとき、どのように解釈するでしょうか。\n",
    "\n",
    "> 東京都千代田区大手町1-1\n",
    "\n",
    "最後に数値がありますが、これが住所であることは多くの日本人が理解できると思います。一方機械では、[日付・時間データの取り扱い](../02/date-and-time)でみたように基本的にはただの文字列として扱い、構成要素を指定しない限りは住所を分解してくれません。\n",
    "\n",
    "位置情報として住所が利用可能な時、パターンマッチを使った分割で住所の要素を分解可能です。これは[カテゴリデータ](../02/categorical)の特徴量エンジニアリングで触れた、Expansion encodingになります。例を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": true
   },
   "outputs": [],
   "source": [
    "\"東京都千代田区大手町1-1\" %>% \n",
    "  stringr::str_split(\"(?<=東京都|道|府|県)\", n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは都道府県名と以下の住所を分割する処理です。必要とする情報はどのレベルまででしょうか。もし市区町村の情報が必要なのであれば、さらなる分割を試みることになります。しかし、都道府県を分離するようなパターンマッチは実装が容易ですが、市区町村、さらに以下の地名を分割していくことは次第に困難になります。対応すべきパターンと例外が出てくるためです。このような場合、あらかじめ住所文字列が分割された辞書を利用することが、近道となることがあります。\n",
    "\n",
    "分解に対して、丸め込み可能な状況も考えられます。特に広域のデータであれば詳細な住所よりも荒い住所で集計、特徴量とした方が良いこともあるかもしれません。データのスケールと問題設定により、どの段階までの情報が必要か検討しましょう。\n",
    "\n",
    "## ジオコーディングと逆ジオコーディング\n",
    "\n",
    "次は、地理空間データをより地理空間データらしく扱うためのコーディングです。住所ではあくまでも文字列でしたが、位置情報に対して地理座標を付加することで空間的な関係が議論できるようになります。こうした各種の情報から座標を付与する、特定する作業をジオコーディングと呼びます。都道府県の名前は一定の面積をもつポリゴンの座標に変換可能なので、ジオコーディングを行うことができます。対して、特定の座標から住所や地名、メッシュコードを判別させる作業を逆ジオコーディングと呼びます。ジオコーディングと逆ジオコーディングは一般に相互変換が可能な処理です。\n",
    "\n",
    "ここでは緯度経度をメッシュコードに, メッシュコードから緯度経度にそれぞれ変換する処理を示します。メッシュコード (標準地域コード、標準地域メッシュ)は国勢調査などの、国内全域を調査するために用いられるポリゴンのことで、規模により名称が異なります。一片の長さがおよそ80kmの第1次地域区画がもっとも大きく、10km、1kmと小さくなっていきます。\n",
    "\n",
    "メッシュコードには位置を特定するための番号が割り振られています。メッシュの大きさによりメッシュコードの長さが異なります。これを使うことで地理空間データとして活用できるようになります。次の表は、標準地域メッシュの体系とメッシュコードの関係を表したものです。\n",
    "\n",
    "| 地域区画 | 標準地域メッシュ| 規模 | 地域メッシュコードの例 |\n",
    "|----------|------------------|-----|:-----------------------|\n",
    "| 第1次地域区画 | | 80km | 5438 |\n",
    "| 第2次地域区画 | (10倍地域メッシュ) | 10km | 543823 |\n",
    "| | 5倍地域メッシュ | 5km | 5438234 |\n",
    "| | 2倍地域メッシュ | 2km | 543823645 |\n",
    "| 第3次地域区画 | 基準地域メッシュ | 1km  | 54382343 |\n",
    "| | 1/2地域メッシュ | 500m | 543823431 |\n",
    "| | 1/4地域メッシュ | 250m | 5438234312 |\n",
    "| | 1/8地域メッシュ | 125m | 54382343123 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "土砂災害・雪崩メッシュデータに含まれる メッシュコード (`meshCode`) は桁数が7です。つまり5kmの範囲をカバーするメッシュコードだということがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hazard %>% \n",
    "  select(meshCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではメッシュコードからメッシュコードの座標を取得してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": true
   },
   "outputs": [],
   "source": [
    "library(jpmesh)\n",
    "sf_hazard <- \n",
    "  df_hazard %>% \n",
    "  head() %>% \n",
    "  jpmesh::meshcode_sf(meshCode)\n",
    "\n",
    "sf_hazard$geometry[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RのsfパッケージはRでのベクタ形式の地理空間オブジェクトを操作するのに優れています。メッシュコードの座標はポリゴンとして `geometry` に格納されています。\n",
    "\n",
    "では今度は緯度経度からメッシュコードを判別させる逆ジオコーディングを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": true
   },
   "outputs": [],
   "source": [
    "mesh <- coords_to_mesh(139.7671, 35.6812)\n",
    "mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メッシュコードが得られましたが、これは地図上に表示してみないことにはどこだかわかりにくいです。確認のために地図上にマッピングしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": false,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "library(mapview)\n",
    "mapview(export_mesh(mesh)) + \n",
    "  mapview(st_sfc(st_point(c(139.7671, 35.6812)), crs = 4326))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/meshcode_mapping.png)\n",
    "\n",
    "座標からの逆ジオコーディングは、データの空間的な配置を特徴量として活用するために有効です。メッシュコードのような変数をカウントし、期間中に災害発生が起こりやすい場所を集計し、モデルに組み込めるかもしれません。これを確かめるために土砂災害・雪崩メッシュデータから、災害種別でのメッシュ件数をカウントした値を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "eval": false,
    "fig.height": 8,
    "hide_input": false,
    "name": "hazard_type_mesh5km"
   },
   "outputs": [],
   "source": [
    "df_hazard_type <- \n",
    "  df_hazard %>%\n",
    "  group_by(hazardType) %>% \n",
    "  count(meshCode) %>% \n",
    "  ungroup() %>% \n",
    "  meshcode_sf(meshCode)\n",
    "\n",
    "ggplot() +\n",
    "  geom_sf(data = df_hazard_type, \n",
    "          aes(fill = n), \n",
    "          color = \"transparent\") +\n",
    "  scale_fill_viridis_c() +\n",
    "  facet_wrap(~ hazardType, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/hazard_type_mesh5km-1.png)\n",
    "\n",
    "やはり災害発生は種類により地域間での差がありそうです。一方で回数には大きな差がないかもしれません（ただしグラフからは読み取れなくなっていますが、最大で60件以上発生しているメッシュがあることも注意が必要です）。\n",
    "ここから得られた情報は次のモデルに活用していきます。また、ジオコーディングにより得た座標は、次の地物間の隣接関係や距離計算のために活用可能です。地理空間データの操作を覚えておくことで、特徴量エンジニアリングの幅が大きく広がります。\n",
    "\n",
    "## 隣接関係\n",
    "\n",
    "地理空間データの分析では、地物間の重なりや接し方、密集、過疎の状態といった隣接関係が議論されます。\n",
    "\n",
    "人口集中地区 (DID) 内外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 距離の計算\n",
    "\n",
    "特定の地物からの距離は目的変数に対して影響していることがあります。\n",
    "\n",
    "あらかじめ計算されていますが、これに追加する形で\n",
    "\n",
    "最寄駅の\n",
    "\n",
    "乗車人数を加えてみることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lp_kanto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参照座標系が異なるために生じる問題\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "## 関連項目\n",
    "\n",
    "## 参考文献\n",
    "\n",
    "- 谷村晋 (2010). 地理空間データ分析 (共立出版)\n",
    "- 古谷知之 (2011). Rによる空間データの統計分析 (朝倉書店)\n",
    "- 瀬谷創、堤盛人 (2014). 空間統計学: 自然科学から人文・社会科学まで (朝倉書店)\n",
    "- Robin Lovelace, Jakub Nowosad, Jannes Muenchow (2019). Geocomputation with R (CRC Press)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
